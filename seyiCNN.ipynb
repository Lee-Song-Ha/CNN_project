{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lee-Song-Ha/CNN_project/blob/main/seyiCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기(드라이브 마운트)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oeKETYMXIvaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "id": "Shq52muPAzYp",
        "outputId": "813a64ef-761b-461c-d704-4e701bdbb4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pictures: 0\n",
            "\n",
            "Number of different labels: 0\n",
            "\n",
            "Labels: []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bcaf7100bf02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilepath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 40 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os.path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from time import perf_counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# 이미지 경로를 데이터 프레임 형태로 만드는 함수\n",
        "dir_ = Path('/content/drive/MyDrive/ColabNotebooks/CNN_Project/imagedata')\n",
        "filepaths = list(dir_.glob(r'**/*.png')) # 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환\n",
        "def proc_img(filepath):\n",
        "    \"\"\"\n",
        "   \t\t이미지데이터의 경로와 label데이터로 데이터프레임 만들기 \n",
        "    \"\"\"\n",
        "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
        "              for i in range(len(filepath))]\n",
        "\n",
        "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
        "    labels = pd.Series(labels, name='Label')\n",
        "\n",
        "    # 경로와 라벨 concatenate, panda에 데이터프레임 합치는 함수.axis=1: 왼쪽+오른쪽으로 합치기\n",
        "    df = pd.concat([filepath, labels], axis=1) \n",
        "                                              \n",
        "\n",
        "    # index 재설정\n",
        "    df = df.sample(frac=1,random_state=0).reset_index(drop = True) # dataframe에 랜덤하게 몇 %의 데이터를 뽑을 것인지.\n",
        "                                                                   # frac=1:모든 데이터를 반환\n",
        "    return df\n",
        "\n",
        "df = proc_img(filepaths)\n",
        "df.head(5)\n",
        "\n",
        "print(f'Number of pictures: {df.shape[0]}\\n') # Number of pictures: 13798\n",
        "print(f'Number of different labels: {len(df.Label.unique())}\\n') #Number of different labels: 8\n",
        "print(f'Labels: {df.Label.unique()}') # unique()는 데이터에 고유값들이 어떠한 종류들이 있는지 알고 싶을 때 사용하는 함수\n",
        "# Labels: ['person' 'airplane' 'car' 'dog' 'cat' 'flower' 'fruit' 'motorbike']\n",
        "\n",
        "# 이미지 데이터 확인\n",
        "fig, axes = plt.subplots(nrows=4, ncols=10, figsize=(15, 7), \n",
        "                        subplot_kw={'xticks': [], 'yticks': []}) # figsize:그래프 사이즈\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(df.Filepath[i]))\n",
        "    ax.set_title(df.Label[i], fontsize = 12)\n",
        "plt.tight_layout(pad=0.5)\n",
        "plt.show()\n",
        "# fig란 figure로써 - 전체 subplot을 말한다. ex) 서브플로안에 몇개의 그래프가 있던지 상관없이  그걸 담는 하나. 전체 사이즈를 말한다.\n",
        "# ax는 axe로써 - 전체 중 낱낱개를 말한다 ex) 서브플롯 안에 2개(a1,a2)의 그래프가 있다면 a1, a2 를 일컬음\n",
        "\n",
        "\n",
        "# Label Category 분포 확인\n",
        "vc = df['Label'].value_counts()\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.barplot(x = vc.index, y = vc, palette = \"rocket\")\n",
        "plt.title(\"Number of pictures of each category\", fontsize = 15)\n",
        "plt.show()\n",
        "\n",
        "#이미지 데이터 Train, Test 데이터로 분류\n",
        "# Training/test split\n",
        "# train_df,test_df = train_test_split(df.sample(frac=0.2), test_size=0.1,random_state=0) #모델링 시간이 오래걸리면 사용\n",
        "train_df,test_df = train_test_split(df, test_size=0.1,random_state=0)\n",
        "train_df.shape,test_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory('/content/drive/MyDrive/ColabNotebooks/CNN_Project/imagedata',\n",
        "                                                 target_size = (256, 256),\n",
        "                                                 batch_size = 32,\n",
        "                                                 color_mode = 'grayscale',\n",
        "                                                 class_mode = 'categorical',subset='training')\n",
        "val_gen  = train_datagen.flow_from_directory('/content/drive/MyDrive/ColabNotebooks/CNN_Project/imagedata',\n",
        "                                                 target_size = (256, 256),\n",
        "                                                 batch_size = 32,\n",
        "                                                 color_mode = 'grayscale',\n",
        "                                                 class_mode = 'categorical',subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b6c2m3waiN-",
        "outputId": "8e735476-a895-4125-dfaf-0e02683d6024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8698 images belonging to 10 classes.\n",
            "Found 2170 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising the CNN\n",
        "# Sequential API는 tensorflow2에서 뉴럴 네트워크를 가장 쉽게 구성할 수 있는 방식\n",
        "# add함수를 이용하면 layer가 순차대로 연결됨.\n",
        "# add함수를 통해 각 layer들은 정확히 하나의 input값만 받을 수 있으며\n",
        "# output 또한 하나의 tensor 형태로만 출력이 가능\n",
        "cnn = tf.keras.models.Sequential() # 케라스는 Sequential을 사용하여 층을 차례대로 쌓음\n",
        "\n",
        "# Step 1 - Convolution 합성곱 층, 32만큼 특성맵이 만들어짐. 입력층이라고 볼 수 있음.\n",
        "# 커널 사이즈 크면 특징 감지하는데 효과가 떨어짐 3이나 5로 함\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[256, 256, 1])) \n",
        "\n",
        "\n",
        "# Step 2 - Pooling\n",
        "# 특성맵 크기 줄이는 작업(압축)\n",
        "# stride 이동하는 크기. stride가 2면 2픽셀씩 이동. 2 by 2 크기가 만들어짐\n",
        "# 풀링의 크기는 2\n",
        "# 높이와 너비 절반 줄어듦\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# Adding convolutional layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "# 풀링으로 크기를 한 번 더 줄임\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "# Flatten() 입력 배열을 1차원으로 펼치는 역할. 연산 같은 거 없고 그냥 펼치는 역할. \n",
        "# 클래스 개수에 맞는 확률값을 얻기 위한 Dense 이전에 실행해야함.\n",
        "# Dense 거치기 전에 먼저 flatten()으로 1차원으로 만들어야함\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Step 4 - Full Connection\n",
        "# 128개의 뉴런 거침.\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Step 5 - Output Layer\n",
        "# 9개의 출력 유닛을 가진 소프트맥스 층 추가, 최종적으로 9개 결과 출력\n",
        "cnn.add(tf.keras.layers.Dense(units=9, activation='softmax')) \n",
        "\n",
        "# Compiling the CNN\n",
        "cnn.compile(optimizer = 'adam',\n",
        "            loss = 'categorical_crossentropy', # 3개 이상의 클래스를 분류할 경우에 사용\n",
        "            metrics = ['accuracy'])\n",
        "cnn.summary()"
      ],
      "metadata": {
        "id": "7nKyl8cZdPen",
        "outputId": "b12cd202-f979-4f26-c734-f6b58e09689e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 254, 254, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 127, 127, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 125, 125, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 62, 62, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 123008)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               15745152  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,755,881\n",
            "Trainable params: 15,755,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 성능확인\n",
        "cnn.fit(x = train_gen, validation_data = val_gen, epochs = 10) #epochs는 학습 횟수"
      ],
      "metadata": {
        "id": "5iuM-f3gbwjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gen():\n",
        "    # 생성기 및 데이터 증강으로 이미지 로드\n",
        "    train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "        validation_split=0.1\n",
        "    )\n",
        "\n",
        "    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    )\n",
        "\n",
        "    train_images = train_generator.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='Filepath', # 파일위치 열이름\n",
        "        y_col='Label', # 클래스 열이름\n",
        "        target_size=(256, 256), # 이미지 사이즈\n",
        "        color_mode='rgb', # 이미지 채널수\n",
        "        class_mode='categorical', # Y값(Label값)\n",
        "        batch_size=32,\n",
        "        shuffle=True, # 데이터를 섞을지 여부\n",
        "        seed=0,\n",
        "        subset='training', # train 인지 val인지 설정\n",
        "        rotation_range=30, # 회전제한 각도 30도\n",
        "        zoom_range=0.15, # 확대 축소 15%\n",
        "        width_shift_range=0.2, # 좌우이동 20%\n",
        "        height_shift_range=0.2, # 상하이동 20%\n",
        "        shear_range=0.15, # 반시계방햐의 각도\n",
        "        horizontal_flip=True, # 좌우 반전 True\n",
        "        fill_mode=\"nearest\"\n",
        "        # 이미지 변경시 보완 방법 (constant, nearest, reflect, wrap) 4개 존재\n",
        "    )\n",
        "\n",
        "    val_images = train_generator.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(256, 256),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=0,\n",
        "        subset='validation',\n",
        "        rotation_range=30,\n",
        "        zoom_range=0.15,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\" #이미지를 축소하거나 이동할 때 공간을 채우는 방식\n",
        "    )\n",
        "\n",
        "    test_images = test_generator.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(256, 256),\n",
        "        color_mode='rgb', \n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    return train_generator,test_generator,train_images,val_images,test_images"
      ],
      "metadata": {
        "id": "w41Yj2fb2t9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    #다양한 모델들 종류!\n",
        "    \"DenseNet121\": {\"model\":tf.keras.applications.DenseNet121, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"DenseNet201\": {\"model\":tf.keras.applications.DenseNet201, \"perf\":0},\n",
        "    \"EfficientNetB0\": {\"model\":tf.keras.applications.EfficientNetB0, \"perf\":0},\n",
        "    \"EfficientNetB1\": {\"model\":tf.keras.applications.EfficientNetB1, \"perf\":0},\n",
        "    \"InceptionV3\": {\"model\":tf.keras.applications.InceptionV3, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"MobileNetV3Large\": {\"model\":tf.keras.applications.MobileNetV3Large, \"perf\":0},\n",
        "    \"ResNet152V2\": {\"model\":tf.keras.applications.ResNet152V2, \"perf\":0},\n",
        "    \"ResNet50\": {\"model\":tf.keras.applications.ResNet50, \"perf\":0},\n",
        "    \"ResNet50V2\": {\"model\":tf.keras.applications.ResNet50V2, \"perf\":0},\n",
        "    \"VGG19\": {\"model\":tf.keras.applications.VGG19, \"perf\":0},\n",
        "    \"VGG16\": {\"model\":tf.keras.applications.VGG16, \"perf\":0},\n",
        "    \"Xception\": {\"model\":tf.keras.applications.Xception, \"perf\":0}\n",
        "}\n",
        "# Create the generators\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "print('\\n')\n",
        "\n",
        "def get_model(model):\n",
        "# Load the pretained model\n",
        "    kwargs =    {'input_shape':(256, 256, 3),\n",
        "                'include_top':False,\n",
        "                'weights':'imagenet',\n",
        "                'pooling':'avg'}\n",
        "    \n",
        "    pretrained_model = model(**kwargs)\n",
        "    pretrained_model.trainable = False # 레이어를 동결 시켜서 훈련중 손실을 최소화 한다.\n",
        "    \n",
        "    inputs = pretrained_model.input\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "    # 라벨 개수가 8개이기 때문에 Dencs도 8로 설정\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Train모델 학습\n",
        "for name, model in models.items():\n",
        "    \n",
        "    # 전이 학습 모델 가져오기\n",
        "    m = get_model(model['model'])\n",
        "    models[name]['model'] = m\n",
        "    \n",
        "    start = perf_counter()\n",
        "    \n",
        "    # 모델 학습\n",
        "    history = m.fit(train_images,validation_data=val_images,epochs=1,verbose=0) #verbose는 진행상황을 보여주는 것\n",
        "    \n",
        "    # 학습시간과 val_accuracy 저장\n",
        "    duration = perf_counter() - start\n",
        "    duration = round(duration,2)\n",
        "    models[name]['perf'] = duration\n",
        "    print(f\"{name:20} trained in {duration} sec\")\n",
        "    \n",
        "    val_acc = history.history['val_accuracy']\n",
        "    models[name]['val_acc'] = [round(v,4) for v in val_acc]"
      ],
      "metadata": {
        "id": "fFSCn0sh3gvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test데이터로 모델 성능 예측\n",
        "#정확도가 떨어지는 것 같은데 이는 그레이 스케일이 아니라 rgb로 받아와서 그런 것 같음 아직 그걸 해결 못 함 \n",
        "for name, model in models.items():\n",
        "    \n",
        "    # Predict the label of the test_images\n",
        "    pred = models[name]['model'].predict(test_images)\n",
        "    pred = np.argmax(pred,axis=1)\n",
        "\n",
        "    # Map the label\n",
        "    labels = (train_images.class_indices)\n",
        "    labels = dict((v,k) for k,v in labels.items())\n",
        "    pred = [labels[k] for k in pred]\n",
        "\n",
        "    y_test = list(test_df.Label)\n",
        "    acc = accuracy_score(y_test,pred)\n",
        "    models[name]['acc'] = round(acc,4)\n",
        "    print(f'**{name} has a {acc * 100:.2f}% accuracy on the test set**')\n",
        "   \n",
        "# Create a DataFrame with the results\n",
        "models_result = []\n",
        "\n",
        "for name, v in models.items():\n",
        "    models_result.append([ name, models[name]['val_acc'][-1], \n",
        "                          models[name]['acc'],\n",
        "                          models[name]['perf']])\n",
        "    \n",
        "df_results = pd.DataFrame(models_result, \n",
        "                          columns = ['model','val_accuracy','accuracy','Training time (sec)'])\n",
        "df_results.sort_values(by='accuracy', ascending=False, inplace=True)\n",
        "df_results.reset_index(inplace=True,drop=True)\n",
        "df_results"
      ],
      "metadata": {
        "id": "JoIs2bO-2Row"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#정확도 비교\n",
        "plt.figure(figsize = (15,5))\n",
        "sns.barplot(x = 'model', y = 'accuracy', data = df_results)\n",
        "plt.title('Accuracy on the test set (after 1 epoch))', fontsize = 15)\n",
        "plt.ylim(0,1)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hwg4tOJH8HdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#시간을 비교\n",
        "plt.figure(figsize = (15,5))\n",
        "sns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\n",
        "plt.title('Training time for each model in sec', fontsize = 15)\n",
        "# plt.ylim(0,20)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SRXQnWJh8QPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_report = classification_report(y_test, pred, zero_division=1)\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "lIV5kmbDJgx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "\n",
        "fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(20, 12),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(test_df.Filepath.iloc[i])) #imshow() 함수를 이용하면 영상을 출력할 수 있습니다.\n",
        "    ax.set_title(f\"True: {test_df.Label.iloc[i].split('_')[0]}\\nPredicted: {pred[i].split('_')[0]}\", fontsize = 15)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5HDRGCle8dHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq /content/drive/MyDrive/ColabNotebooks/CNN_Project/imagedata/image.zip -d /content/drive/MyDrive/ColabNotebooks/CNN_Project/imagedata"
      ],
      "metadata": {
        "id": "dhBUru1qIXBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('경로')"
      ],
      "metadata": {
        "id": "nCoXEEEqd6qf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}